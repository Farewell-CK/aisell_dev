#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ•°æ®åº“è¿ç§»è„šæœ¬
å°†MySQLæ•°æ®åº“è¿ç§»åˆ°SQLiteï¼ŒåŒ…å«æ•°æ®è„±æ•å’Œé™åˆ¶åŠŸèƒ½
"""

import os
import sys
import shutil
import hashlib
import random
from datetime import datetime

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from tools.database_migration import DatabaseMigrator
from sqlalchemy import create_engine, text
import json
import logging

logger = logging.getLogger(__name__)

class SensitiveDataMigrator(DatabaseMigrator):
    """æ•æ„Ÿæ•°æ®å¤„ç†è¿ç§»å™¨"""
    
    def __init__(self, source_config_path='configs/database.yaml'):
        super().__init__(source_config_path)
        
        # å®šä¹‰æ•æ„Ÿå­—æ®µæ˜ å°„
        self.sensitive_fields = {
            # å¾®ä¿¡ç›¸å…³æ•æ„Ÿå­—æ®µ
            'wechat_id': 'wechat_id',
            'wechat_no': 'wechat_no', 
            'wechat_nickname': 'wechat_nickname',
            'wechat_group_id': 'wechat_group_id',
            'wechat_group_nickname': 'wechat_group_nickname',
            'belong_wechat_id': 'belong_wechat_id',
            'source_wechat_id': 'source_wechat_id',
            'sender_wechat_id': 'sender_wechat_id',
            
            # å…¬å¸ç›¸å…³æ•æ„Ÿå­—æ®µ
            'company_name': 'company_name',
            'company_id': 'company_id',
            
            # ç”¨æˆ·ç›¸å…³æ•æ„Ÿå­—æ®µ
            'user_id': 'user_id',
            'username': 'username',
            'name': 'name',
            'mobile_no': 'mobile_no',
            'phone': 'phone',
            'email': 'email',
            
            # èŠå¤©è®°å½•ç›¸å…³æ•æ„Ÿå­—æ®µ
            'content': 'content',
            'text': 'text',
            'message': 'message',
            'chat_content': 'chat_content',
            'reply_content': 'reply_content',
            
            # å…¶ä»–æ•æ„Ÿå­—æ®µ
            'password': 'password',
            'token': 'token',
            'api_key': 'api_key',
            'secret': 'secret'
        }
        
        # è„±æ•æ•°æ®ç¼“å­˜ï¼Œç¡®ä¿ç›¸åŒå€¼è„±æ•åä¿æŒä¸€è‡´
        self.masking_cache = {}
    
    def mask_sensitive_data(self, value, field_name):
        """
        å¯¹æ•æ„Ÿæ•°æ®è¿›è¡Œè„±æ•å¤„ç†
        
        Args:
            value: åŸå§‹å€¼
            field_name: å­—æ®µå
            
        Returns:
            è„±æ•åçš„å€¼
        """
        if value is None:
            return None
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯æ•æ„Ÿå­—æ®µ
        if field_name.lower() not in [k.lower() for k in self.sensitive_fields.keys()]:
            return value
        
        # åˆ›å»ºç¼“å­˜é”®
        cache_key = f"{field_name}_{str(value)}"
        
        # å¦‚æœå·²ç»è„±æ•è¿‡ï¼Œè¿”å›ç¼“å­˜çš„ç»“æœ
        if cache_key in self.masking_cache:
            return self.masking_cache[cache_key]
        
        # æ ¹æ®å­—æ®µç±»å‹è¿›è¡Œä¸åŒçš„è„±æ•å¤„ç†
        if field_name.lower() in ['wechat_id', 'wechat_no', 'belong_wechat_id', 'source_wechat_id', 'sender_wechat_id']:
            # å¾®ä¿¡IDè„±æ•ï¼šä¿æŒæ ¼å¼ä½†æ›¿æ¢å†…å®¹
            masked_value = f"wx_{hashlib.md5(str(value).encode()).hexdigest()[:8]}"
        elif field_name.lower() in ['wechat_nickname', 'wechat_group_nickname']:
            # å¾®ä¿¡æ˜µç§°è„±æ•
            masked_value = f"ç”¨æˆ·_{hashlib.md5(str(value).encode()).hexdigest()[:6]}"
        elif field_name.lower() in ['company_name', 'name']:
            # å…¬å¸åå’Œå§“åè„±æ•
            masked_value = f"å…¬å¸_{hashlib.md5(str(value).encode()).hexdigest()[:6]}"
        elif field_name.lower() in ['mobile_no', 'phone']:
            # æ‰‹æœºå·è„±æ•ï¼šä¿ç•™å‰3ä½å’Œå4ä½
            phone_str = str(value)
            if len(phone_str) >= 7:
                masked_value = phone_str[:3] + '*' * (len(phone_str) - 7) + phone_str[-4:]
            else:
                masked_value = '*' * len(phone_str)
        elif field_name.lower() in ['email']:
            # é‚®ç®±è„±æ•ï¼šä¿ç•™@å‰çš„ç¬¬ä¸€ä¸ªå­—ç¬¦å’Œ@åçš„åŸŸå
            email_str = str(value)
            if '@' in email_str:
                username, domain = email_str.split('@', 1)
                masked_value = f"{username[0]}***@{domain}"
            else:
                masked_value = '***@example.com'
        elif field_name.lower() in ['password', 'token', 'api_key', 'secret']:
            # å¯†ç ç­‰æ•æ„Ÿä¿¡æ¯å®Œå…¨è„±æ•
            masked_value = '***MASKED***'
        elif field_name.lower() in ['content', 'text', 'message', 'chat_content', 'reply_content']:
            # èŠå¤©å†…å®¹è„±æ•ï¼šä¿ç•™é•¿åº¦ä½†æ›¿æ¢å†…å®¹
            content_str = str(value)
            if len(content_str) > 20:
                masked_value = f"[è„±æ•å†…å®¹_{len(content_str)}å­—ç¬¦]"
            else:
                masked_value = '[è„±æ•å†…å®¹]'
        else:
            # å…¶ä»–æ•æ„Ÿå­—æ®µï¼šä½¿ç”¨å“ˆå¸Œè„±æ•
            masked_value = f"MASKED_{hashlib.md5(str(value).encode()).hexdigest()[:8]}"
        
        # ç¼“å­˜è„±æ•ç»“æœ
        self.masking_cache[cache_key] = masked_value
        return masked_value
    
    def get_table_data(self, table_name, limit=10):
        """
        è·å–è¡¨æ•°æ®ï¼Œé™åˆ¶ä¸º10è¡Œï¼Œå¹¶å¯¹æ•æ„Ÿå­—æ®µè¿›è¡Œè„±æ•
        
        Args:
            table_name (str): è¡¨å
            limit (int): æ•°æ®é™åˆ¶ï¼Œé»˜è®¤10è¡Œ
            
        Returns:
            list: è„±æ•åçš„æ•°æ®åˆ—è¡¨
        """
        try:
            query = f"SELECT * FROM {table_name} LIMIT {limit}"
            
            with self.source_engine.connect() as connection:
                result = connection.execute(text(query))
                columns = result.keys()
                data = []
                
                for row in result:
                    row_dict = dict(zip(columns, row))
                    
                    # å¯¹æ•æ„Ÿå­—æ®µè¿›è¡Œè„±æ•
                    masked_row = {}
                    for field_name, value in row_dict.items():
                        masked_row[field_name] = self.mask_sensitive_data(value, field_name)
                    
                    data.append(masked_row)
                
                logger.info(f"ä»è¡¨ {table_name} è·å–äº† {len(data)} æ¡è®°å½•ï¼ˆå·²è„±æ•ï¼‰")
                return data
                
        except Exception as e:
            logger.error(f"è·å–è¡¨ {table_name} æ•°æ®å¤±è´¥: {e}")
            return []
    
    def migrate_to_sqlite(self, target_db_path='database/sale.db', tables=None):
        """
        è¿ç§»åˆ°SQLiteæ•°æ®åº“ï¼Œæ¯ä¸ªè¡¨é™åˆ¶10è¡Œæ•°æ®å¹¶è„±æ•
        
        Args:
            target_db_path (str): SQLiteæ•°æ®åº“æ–‡ä»¶è·¯å¾„
            tables (list): è¦è¿ç§»çš„è¡¨ååˆ—è¡¨ï¼ŒNoneè¡¨ç¤ºè¿ç§»æ‰€æœ‰è¡¨
        """
        # ç¡®ä¿ç›®æ ‡ç›®å½•å­˜åœ¨
        target_dir = os.path.dirname(target_db_path)
        if target_dir:
            os.makedirs(target_dir, exist_ok=True)
        
        # åˆ›å»ºSQLiteå¼•æ“
        sqlite_url = f"sqlite:///{target_db_path}"
        target_engine = create_engine(sqlite_url, echo=False)
        
        # è·å–è¦è¿ç§»çš„è¡¨
        if tables is None:
            tables = self.get_table_names()
        
        logger.info(f"å¼€å§‹è¿ç§» {len(tables)} ä¸ªè¡¨åˆ°SQLiteï¼ˆæ¯ä¸ªè¡¨é™åˆ¶10è¡Œï¼Œå·²è„±æ•ï¼‰: {target_db_path}")
        
        for table_name in tables:
            try:
                logger.info(f"æ­£åœ¨è¿ç§»è¡¨: {table_name}")
                
                # è·å–è¡¨ç»“æ„
                schema = self.get_table_schema(table_name)
                if not schema:
                    logger.warning(f"è·³è¿‡è¡¨ {table_name}ï¼Œæ— æ³•è·å–ç»“æ„")
                    continue
                
                # åˆ›å»ºè¡¨
                self._create_sqlite_table(target_engine, table_name, schema)
                
                # è¿ç§»æ•°æ®ï¼ˆé™åˆ¶10è¡Œå¹¶è„±æ•ï¼‰
                data = self.get_table_data(table_name, limit=10)
                if data:
                    self._insert_data_to_sqlite(target_engine, table_name, data)
                
                logger.info(f"è¡¨ {table_name} è¿ç§»å®Œæˆï¼ˆ{len(data)} æ¡è®°å½•ï¼‰")
                
            except Exception as e:
                logger.error(f"è¿ç§»è¡¨ {table_name} å¤±è´¥: {e}")
        
        logger.info("SQLiteè¿ç§»å®Œæˆï¼ˆæ•°æ®å·²è„±æ•ï¼‰")
        return target_db_path
    
    def export_to_json(self, output_path='database_export_masked.json', tables=None):
        """
        å¯¼å‡ºæ•°æ®åº“åˆ°JSONæ–‡ä»¶ï¼ŒåŒ…å«è„±æ•æ•°æ®
        
        Args:
            output_path (str): è¾“å‡ºJSONæ–‡ä»¶è·¯å¾„
            tables (list): è¦å¯¼å‡ºçš„è¡¨ååˆ—è¡¨
        """
        if tables is None:
            tables = self.get_table_names()
        
        export_data = {
            'export_time': datetime.now().isoformat(),
            'source_database': self.source_config.get('database', {}).get('name', 'unknown'),
            'data_masked': True,
            'data_limit_per_table': 10,
            'tables': {}
        }
        
        for table_name in tables:
            try:
                logger.info(f"æ­£åœ¨å¯¼å‡ºè¡¨: {table_name}")
                
                # è·å–è¡¨ç»“æ„
                schema = self.get_table_schema(table_name)
                
                # è·å–è¡¨æ•°æ®ï¼ˆé™åˆ¶10è¡Œå¹¶è„±æ•ï¼‰
                data = self.get_table_data(table_name, limit=10)
                
                export_data['tables'][table_name] = {
                    'schema': schema,
                    'data': data,
                    'record_count': len(data),
                    'data_masked': True
                }
                
                logger.info(f"è¡¨ {table_name} å¯¼å‡ºå®Œæˆï¼ŒåŒ…å« {len(data)} æ¡è„±æ•è®°å½•")
                
            except Exception as e:
                logger.error(f"å¯¼å‡ºè¡¨ {table_name} å¤±è´¥: {e}")
        
        # ä¿å­˜åˆ°JSONæ–‡ä»¶
        output_dir = os.path.dirname(output_path)
        if output_dir:
            os.makedirs(output_dir, exist_ok=True)
        
        # è‡ªå®šä¹‰JSONç¼–ç å™¨å¤„ç†datetimeã€byteså’ŒDecimalå¯¹è±¡
        class DateTimeEncoder(json.JSONEncoder):
            def default(self, obj):
                if isinstance(obj, datetime):
                    return obj.isoformat()
                elif isinstance(obj, bytes):
                    return obj.decode('utf-8', errors='ignore')
                elif hasattr(obj, '__float__'):
                    return float(obj)
                return super().default(obj)
        
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(export_data, f, ensure_ascii=False, indent=2, cls=DateTimeEncoder)
        
        logger.info(f"æ•°æ®åº“å¯¼å‡ºå®Œæˆï¼ˆå·²è„±æ•ï¼‰: {output_path}")
        return output_path

def backup_original_config():
    """å¤‡ä»½åŸå§‹é…ç½®æ–‡ä»¶"""
    original_config = 'configs/database.yaml'
    backup_config = f'configs/database_backup_{datetime.now().strftime("%Y%m%d_%H%M%S")}.yaml'
    
    if os.path.exists(original_config):
        shutil.copy2(original_config, backup_config)
        print(f"âœ… åŸå§‹é…ç½®æ–‡ä»¶å·²å¤‡ä»½åˆ°: {backup_config}")
        return backup_config
    return None

def switch_to_sqlite():
    """åˆ‡æ¢åˆ°SQLiteé…ç½®"""
    sqlite_config = 'configs/database_sqlite.yaml'
    target_config = 'configs/database.yaml'
    
    if os.path.exists(sqlite_config):
        shutil.copy2(sqlite_config, target_config)
        print("âœ… å·²åˆ‡æ¢åˆ°SQLiteé…ç½®")
        return True
    else:
        print("âŒ SQLiteé…ç½®æ–‡ä»¶ä¸å­˜åœ¨")
        return False

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¼€å§‹æ•°æ®åº“è¿ç§»æµç¨‹ï¼ˆåŒ…å«æ•°æ®è„±æ•ï¼‰...")
    print("=" * 60)
    print("ğŸ“‹ è¿ç§»è®¾ç½®:")
    print("   - æ¯ä¸ªè¡¨é™åˆ¶10è¡Œæ•°æ®")
    print("   - æ•æ„Ÿå­—æ®µè‡ªåŠ¨è„±æ•")
    print("   - å¾®ä¿¡IDã€æ˜µç§°ã€å…¬å¸åç­‰æ•æ„Ÿä¿¡æ¯å°†è¢«æ›¿æ¢")
    print("=" * 60)
    
    try:
        # 1. å¤‡ä»½åŸå§‹é…ç½®
        backup_file = backup_original_config()
        
        # 2. æ¢å¤MySQLé…ç½®ç”¨äºè¿ç§»
        if backup_file:
            shutil.copy2(backup_file, 'configs/database.yaml')
            print("âœ… å·²æ¢å¤MySQLé…ç½®ç”¨äºè¿ç§»")
        
        # 3. åˆ›å»ºæ•æ„Ÿæ•°æ®å¤„ç†è¿ç§»å™¨
        print("ğŸ“Š æ­£åœ¨åˆ†ææºæ•°æ®åº“...")
        migrator = SensitiveDataMigrator()
        
        # 4. ç”Ÿæˆè¿ç§»æŠ¥å‘Š
        print("ğŸ“‹ ç”Ÿæˆè¿ç§»æŠ¥å‘Š...")
        report_path = migrator.generate_migration_report()
        print(f"âœ… è¿ç§»æŠ¥å‘Šå·²ç”Ÿæˆ: {report_path}")
        
        # 5. å¯¼å‡ºæ•°æ®åˆ°JSONï¼ˆè„±æ•ï¼‰
        print("ğŸ“¤ å¯¼å‡ºæ•°æ®åˆ°JSONï¼ˆå·²è„±æ•ï¼‰...")
        json_path = migrator.export_to_json()
        print(f"âœ… æ•°æ®å¯¼å‡ºå®Œæˆ: {json_path}")
        
        # 6. è¿ç§»åˆ°SQLiteï¼ˆè„±æ•ï¼‰
        print("ğŸ”„ å¼€å§‹è¿ç§»åˆ°SQLiteï¼ˆæ•°æ®å·²è„±æ•ï¼‰...")
        sqlite_path = migrator.migrate_to_sqlite()
        print(f"âœ… SQLiteæ•°æ®åº“åˆ›å»ºå®Œæˆ: {sqlite_path}")
        
        # 7. åˆ‡æ¢åˆ°SQLiteé…ç½®
        print("âš™ï¸ åˆ‡æ¢åˆ°SQLiteé…ç½®...")
        if switch_to_sqlite():
            print("âœ… é…ç½®åˆ‡æ¢å®Œæˆ")
        else:
            print("âŒ é…ç½®åˆ‡æ¢å¤±è´¥")
        
        print("=" * 60)
        print("ğŸ‰ è¿ç§»å®Œæˆï¼")
        print(f"ğŸ“ SQLiteæ•°æ®åº“æ–‡ä»¶: {sqlite_path}")
        print(f"ğŸ“‹ è¿ç§»æŠ¥å‘Š: {report_path}")
        print(f"ğŸ“¤ æ•°æ®å¤‡ä»½ï¼ˆå·²è„±æ•ï¼‰: {json_path}")
        if backup_file:
            print(f"ğŸ’¾ åŸå§‹é…ç½®å¤‡ä»½: {backup_file}")
        
        print("\nğŸ”’ æ•°æ®å®‰å…¨è¯´æ˜:")
        print("   - æ‰€æœ‰æ•æ„Ÿæ•°æ®å·²è„±æ•å¤„ç†")
        print("   - æ¯ä¸ªè¡¨åªä¿ç•™10è¡Œç¤ºä¾‹æ•°æ®")
        print("   - å¾®ä¿¡IDã€æ˜µç§°ã€å…¬å¸åç­‰æ•æ„Ÿä¿¡æ¯å·²è¢«æ›¿æ¢")
        print("   - èŠå¤©è®°å½•å†…å®¹å·²è¢«è„±æ•")
        
        print("\nğŸ“ ä¸‹ä¸€æ­¥æ“ä½œ:")
        print("1. æµ‹è¯•åº”ç”¨æ˜¯å¦æ­£å¸¸å·¥ä½œ")
        print("2. å¦‚æœæµ‹è¯•é€šè¿‡ï¼Œå¯ä»¥åˆ é™¤MySQLæ•°æ®åº“")
        print("3. å¦‚æœéœ€è¦å›æ»šï¼Œå¯ä»¥æ¢å¤å¤‡ä»½çš„é…ç½®æ–‡ä»¶")
        
    except Exception as e:
        print(f"âŒ è¿ç§»å¤±è´¥: {e}")
        print("è¯·æ£€æŸ¥æ•°æ®åº“è¿æ¥é…ç½®å’Œç½‘ç»œè¿æ¥")
        return False
    
    return True

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1) 