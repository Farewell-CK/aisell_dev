{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "项目名称：AI流程图匠——智能可视化协作平台\n",
    "Slogan： \"用自然语言定义流程，让AI为您绘制世界！\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install mermaid-py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mermaid 环境测试\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mermaid as md\n",
    "from mermaid.graph import Graph\n",
    "\n",
    "render = md.Mermaid(\"\"\"\n",
    "graph TD\n",
    "    subgraph \"财务票据数据采集与预处理\"\n",
    "        A[\"文件输入 (图片, PDF, Word 等)\"] --> B[\"转换为图片格式\"];\n",
    "        B --> C[\"PaddleOCR进行文本处理\"];\n",
    "    end\n",
    "    subgraph \"结构化与提示词工程\"\n",
    "        C --> D[\"大模型结构化OCR识别结果\"];\n",
    "        D --> E[\"大模型进行规则判断\"];\n",
    "        E --> F[\"输出判断结果\"];\n",
    "    end\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "render "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "render.to_png(\"work/output/test.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 大模型调用测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = \"ae467bfa991e56e0e996a60820b93e9455f7e6bd\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "你好！AI Studio 是百度飞桨深度学习平台推出的一个集在线编程、实训项目、竞赛、交流社区于一体的实训 AI 开发平台。以下是一些 AI Studio 的主要特点和功能介绍：\n",
      "\n",
      "### 主要特点\n",
      "\n",
      "1. **在线编程环境**：\n",
      "   - 提供云端 Jupyter Notebook 编程环境，无需在本地安装复杂的开发环境。\n",
      "   - 支持多种编程语言，特别是 Python，以及深度学习框架如 PaddlePaddle。\n",
      "\n",
      "2. **免费算力资源**：\n",
      "   - 为用户提供免费的 GPU 算力资源，支持深度学习模型的训练和推理。\n",
      "   - 根据用户的使用情况和贡献，可以提供更多的算力资源奖励。\n",
      "\n",
      "3. **丰富的实训项目**：\n",
      "   - 提供涵盖计算机视觉、自然语言处理、推荐系统等多个领域的实训项目。\n",
      "   - 每个项目都包含详细的教程、代码示例和数据集，帮助用户快速上手。\n",
      "\n",
      "4. **竞赛平台**：\n",
      "   - 定期举办各种 AI 竞赛，涵盖不同的应用场景和技术挑战。\n",
      "   - 提供竞赛数据集、评估标准和排行榜，鼓励用户参与并提升自己的技能。\n",
      "\n",
      "5. **交流社区**：\n",
      "   - 拥有活跃的开发者社区，用户可以在其中提问、分享经验、交流想法。\n",
      "   - 提供论坛、博客、问答等多种形式的交流平台。\n",
      "\n",
      "### 功能介绍\n",
      "\n",
      "1. **代码编辑与运行**：\n",
      "   - 支持代码自动补全、语法高亮、多行编辑等高级编辑功能。\n",
      "   - 可以直接在云端运行代码，查看输出结果和日志。\n",
      "\n",
      "2. **数据集管理**：\n",
      "   - 提供数据集上传、下载、管理功能，方便用户处理自己的数据集。\n",
      "   - 支持多种数据格式，如 CSV、JSON、图像等。\n",
      "\n",
      "3. **模型训练与部署**：\n",
      "   - 支持使用 PaddlePaddle 框架进行模型训练，提供训练日志、模型保存和加载功能。\n",
      "   - 提供模型部署工具，可以将训练好的模型部署到云端或本地服务器。\n",
      "\n",
      "4. **版本管理**：\n",
      "   - 支持代码和数据集的版本管理，方便用户追踪和回滚到之前的版本。\n",
      "   - 提供协作功能，多个用户可以一起开发同一个项目。\n",
      "\n",
      "### 适用人群\n",
      "\n",
      "- AI 初学者：通过实训项目和教程，快速入门深度学习。\n",
      "- 开发者：利用在线编程环境和免费算力资源，进行深度学习模型的开发和优化。\n",
      "- 数据科学家：处理和分析大规模数据集，进行数据挖掘和机器学习实验。\n",
      "- 学生和研究者：参与竞赛、交流学术成果，提升 AI 技能。\n",
      "\n",
      "希望这些信息能帮助你更好地了解 AI Studio！如果你有任何其他问题或需要进一步的帮助，请随时告诉我。\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "     api_key=api_key,  # 含有 AI Studio 访问令牌的环境变量，https://aistudio.baidu.com/account/accessToken,\n",
    "     base_url=\"https://aistudio.baidu.com/llm/lmapi/v3\",  # aistudio 大模型 api 服务域名\n",
    ")\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {'role': 'system', 'content': '你是 AI Studio 实训AI开发平台的开发者助理，你精通开发相关的知识，负责给开发者提供搜索帮助建议。'},\n",
    "        {'role': 'user', 'content': '你好，请介绍一下AI Studio'}\n",
    "    ],\n",
    "    model=\"ernie-3.5-8k\",\n",
    ")\n",
    "\n",
    "print(chat_completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 智能体搭建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import os\n",
    "from google.adk.agents import LoopAgent, LlmAgent, BaseAgent, SequentialAgent\n",
    "from google.genai import types\n",
    "from google.adk.runners import InMemoryRunner\n",
    "from google.adk.sessions import InMemorySessionService, DatabaseSessionService, Session\n",
    "from google.adk.runners import Runner\n",
    "from google.adk.models.lite_llm import LiteLlm # 用于多模型支持\n",
    "from google.adk.agents.invocation_context import InvocationContext\n",
    "from google.adk.tools.tool_context import ToolContext\n",
    "from typing import AsyncGenerator, Optional\n",
    "from google.adk.events import Event, EventActions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Constants ---\n",
    "APP_NAME = \"draw_picture_v3\" # New App Name\n",
    "USER_ID = \"dev_user_01\"\n",
    "SESSION_ID_BASE = \"draw_picture_v3\" # New Base Session ID\n",
    "MODEL = \"ernie-4.5-turbo-32k\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from google.adk.models.lite_llm import LiteLlm\n",
    "\n",
    "ernie_model = LiteLlm(\n",
    "    model=f\"openai/{MODEL}\",\n",
    "    base_url=\"https://aistudio.baidu.com/llm/lmapi/v3\",\n",
    "    api_key=\"ae467bfa991e56e0e996a60820b93e9455f7e6bd\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Tool Definition ---\n",
    "def exit_loop(tool_context: ToolContext):\n",
    "  \"\"\"当成功生成图表时，调用该工具，表明迭代结束\"\"\"\n",
    "  print(f\"  [Tool Call] exit_loop triggered by {tool_context.agent_name}\")\n",
    "  tool_context.actions.escalate = True\n",
    "  # Return empty dict as tools should typically return JSON-serializable output\n",
    "  return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_prompt = \"\"\"\n",
    "# 角色定位\n",
    "你是一位专业的 Mermaid 图表架构师，擅长将复杂流程转化为清晰、专业的可视化图表。你精通各类图表语法，并能根据需求选择最合适的图表类型。\n",
    "\n",
    "\n",
    "# 工作流程\n",
    "1. 需求分析\n",
    "   - 仔细理解用户描述的业务场景和需求\n",
    "   - 识别关键实体、流程和关系\n",
    "   - 确定图表的核心目标和展示重点\n",
    "\n",
    "2. 图表选型\n",
    "   - 根据需求选择最合适的图表类型：\n",
    "     * flowchart：适合展示流程、决策和分支\n",
    "     * sequenceDiagram：适合展示时序和交互\n",
    "     * gantt：适合展示项目计划和进度\n",
    "     * mindmap：适合展示思维导图和层级关系\n",
    "     * classDiagram：适合展示类图和对象关系\n",
    "     * erDiagram：适合展示实体关系\n",
    "   - 说明选择理由和图表优势\n",
    "\n",
    "3. 代码生成\n",
    "   - 编写结构清晰、注释完整的 Mermaid 代码\n",
    "   - 遵循最佳实践和命名规范\n",
    "   - 确保代码的可读性和可维护性\n",
    "   - 优化图表布局和视觉效果\n",
    "\n",
    "4. 交付规范\n",
    "   - 仅提供完整的 Mermaid 代码\n",
    "   - 不包含额外的文字说明\n",
    "   - 确保代码可直接复制使用\n",
    "\n",
    "# 注意事项\n",
    "1. 保持代码简洁，避免过度复杂的嵌套\n",
    "2. 使用清晰的命名和注释\n",
    "3. 确保图表逻辑完整，不遗漏关键步骤\n",
    "4. 适当使用子图(subgraph)组织复杂流程\n",
    "\n",
    "需求如下：\n",
    "{demand_analysis_result}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_agent = LlmAgent(\n",
    "    name = \"code_agent\",\n",
    "    model = ernie_model,\n",
    "    description = \"根据用户描述，生成 Mermaid 代码\",\n",
    "    instruction = code_prompt,\n",
    "    tools = [exit_loop],\n",
    "    output_key = \"generated_code\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "render_prompt = \"\"\"\n",
    "# 角色定位\n",
    "你是一位专业的 Mermaid 图表渲染工程师，精通各类图表的渲染和优化技术。你的主要职责是将 Mermaid 代码转换为高质量的可视化图表。\n",
    "\n",
    "代码如下：\n",
    "```mermaid\n",
    "{generated_code}\n",
    "```\n",
    "\n",
    "# 工作流程\n",
    "1. 调用 render_mermaid 工具对代码进行渲染\n",
    "2. 验证渲染结果\n",
    "3. 如果渲染成功，则调用 exit_loop 工具，退出迭代并返回图表图片的保存路径\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mermaid as md\n",
    "from mermaid.graph import Graph\n",
    "\n",
    "def render_mermaid(code: str, path=\"D:/WORK/workspace/aisell/aisell_dev/logs/mermaid.png\"):\n",
    "    \"\"\"\n",
    "    根据code_agent生成的代码，渲染出图表。\n",
    "    Args:\n",
    "        code: str, Mermaid 代码\n",
    "        path: str, 图表图片的保存路径\n",
    "    Returns:\n",
    "        dict, 如果保存成功则返回图表图片的保存路径，如果失败则返回错误信息\n",
    "    \"\"\"\n",
    "    try:\n",
    "        render = md.Mermaid(code).to_png(path)\n",
    "        return {\n",
    "        \"status\": \"success\",\n",
    "        \"path\": path\n",
    "    }\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"status\": \"error\",\n",
    "            \"message\": str(e)\n",
    "        }\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "render_agent = LlmAgent(\n",
    "    name = \"render_agent\",\n",
    "    model = ernie_model,\n",
    "    description = \"根据code_agent生成的代码，渲染出图表\",\n",
    "    instruction = render_prompt,\n",
    "    tools = [exit_loop, render_mermaid],\n",
    "    output_key = \"rendered_picture_path\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow_picture_loop = LoopAgent(\n",
    "    name = \"flow_picture_loop\",\n",
    "    sub_agents = [code_agent, render_agent],\n",
    "    max_iterations=5 # Limit loops\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "demand_analysis_prompt = \"\"\"\n",
    "# 角色定位\n",
    "你是一位专业的流程图需求分析师，擅长通过对话深入理解用户的业务需求，并将其转化为清晰的图表需求规格。\n",
    "\n",
    "# 核心能力\n",
    "1. 需求挖掘与分析\n",
    "   - 通过提问引导用户明确需求\n",
    "   - 识别业务场景中的关键流程和节点\n",
    "   - 理解业务规则和约束条件\n",
    "\n",
    "2. 需求结构化\n",
    "   - 将用户描述转化为结构化的需求\n",
    "   - 识别流程中的关键实体和关系\n",
    "   - 明确流程的起点和终点\n",
    "\n",
    "3. 需求验证\n",
    "   - 确认需求理解的准确性\n",
    "   - 识别潜在的问题和风险\n",
    "   - 提出优化建议\n",
    "\n",
    "# 工作流程\n",
    "1. 需求收集\n",
    "   - 通过开放式问题了解用户意图\n",
    "   - 收集业务流程的基本信息\n",
    "   - 确认关键业务场景\n",
    "\n",
    "2. 需求分析\n",
    "   - 识别核心业务流程\n",
    "   - 确定关键决策点\n",
    "   - 明确业务规则和约束\n",
    "\n",
    "3. 需求传递\n",
    "   - 将分析结果传递给代码生成智能体\n",
    "   - 确保需求描述的准确性和完整性\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "demand_analysis_agent = LlmAgent(\n",
    "    name = \"demand_analysis_agent\",\n",
    "    model = ernie_model,\n",
    "    description = \"根据用户描述，分析需求\",\n",
    "    instruction = demand_analysis_prompt,\n",
    "    output_key = \"demand_analysis_result\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_agent = SequentialAgent(\n",
    "    name = \"root_agent\",\n",
    "    sub_agents = [demand_analysis_agent, flow_picture_loop],\n",
    "    description = \"根据用户描述，生成流程图\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def call_agent_async(query, runner, user_id, session_id):\n",
    "    \"\"\"Sends a query to the agent and prints the final response.\"\"\"\n",
    "    print(f\"User Query: {query}\")\n",
    "\n",
    "    # Prepare the user's message in ADK format\n",
    "    content = types.Content(role='user', parts=[types.Part(text=query)])\n",
    "\n",
    "    final_response_text = \"智能体没有产生最终响应。\" # 默认值\n",
    "\n",
    "    # 关键概念：run_async 执行智能体逻辑并产生事件。\n",
    "    # 我们遍历事件以找到最终答案。\n",
    "    async for event in runner.run_async(user_id=user_id, session_id=session_id, new_message=content):\n",
    "        # 你可以取消注释下面的行以查看执行期间的*所有*事件\n",
    "        print(f\"  [事件] 作者：{event.author}，类型：{type(event).__name__}，最终：{event.is_final_response()}，内容：{event.content}\")\n",
    "\n",
    "        # 关键概念：is_final_response() 标记轮次的结束消息。\n",
    "        if event.is_final_response():\n",
    "            if event.content and event.content.parts:\n",
    "                # 假设第一部分中的文本响应\n",
    "                final_response_text = event.content.parts[0].text\n",
    "            elif event.actions and event.actions.escalate: # 处理潜在错误/升级\n",
    "                final_response_text = f\"智能体升级：{event.error_message or '无特定消息。'}\"\n",
    "                # 如果需要，在这里添加更多检查（例如，特定错误代码）\n",
    "            break # 找到最终响应后停止处理事件\n",
    "    print(f\"Agent Response: {final_response_text}\")\n",
    "    return final_response_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Session(id='draw_picture_v3', app_name='draw_picture_v3', user_id='dev_user_01', state={}, events=[], last_update_time=1749785911.2398827)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 创建会话服务，为了使智能体能够记住对话历史，我们需要创建一个会话服务。将聊天存到内存当中\n",
    "session_service = InMemorySessionService()\n",
    "\n",
    "await session_service.create_session(app_name=APP_NAME, user_id=USER_ID, session_id=SESSION_ID_BASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_runner = Runner(\n",
    "    agent = root_agent,\n",
    "    app_name = APP_NAME,\n",
    "    session_service = session_service\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User Query: 帮我画一个RAG的流程图\n",
      "  [事件] 作者：demand_analysis_agent，类型：Event，最终：True，内容：parts=[Part(video_metadata=None, thought=None, inline_data=None, file_data=None, thought_signature=None, code_execution_result=None, executable_code=None, function_call=None, function_response=None, text='好的！为了更精准地为您设计RAG（Retrieval-Augmented Generation，检索增强生成）流程图，我需要进一步了解一些关键信息。以下是几个引导性问题，帮助我们明确需求：\\n\\n---\\n\\n### **需求收集阶段**\\n1. **核心场景**  \\n   - 您的RAG流程具体应用于哪个领域？（如智能问答、文档摘要、知识库检索等）  \\n   - 是否有特定的输入/输出要求？（例如用户输入问题，输出结构化答案）\\n\\n2. **流程细节**  \\n   - **检索阶段**：  \\n     - 使用的检索技术是什么？（如向量相似度检索、关键词匹配、BM25等）  \\n     - 检索的数据源是什么？（数据库、文档库、API等）  \\n     - 是否有过滤或排序规则？（如时间、相关性、权重）  \\n   - **增强阶段**：  \\n     - 如何将检索结果与生成模型结合？（如直接拼接、加权融合、多轮迭代）  \\n     - 是否需要人工干预或后处理？（如答案校验、格式化）  \\n   - **生成阶段**：  \\n     - 使用的生成模型是什么？（如GPT-4、LLaMA、自定义模型）  \\n     - 输出格式是否有要求？（如JSON、自然语言、图表）  \\n\\n3. **关键约束**  \\n   - 是否有性能要求？（如响应时间、并发量）  \\n   - 是否有安全或合规性限制？（如数据脱敏、访问控制）  \\n   - 是否有异常处理需求？（如检索失败、生成结果不可用时的回退策略）\\n\\n---\\n\\n### **需求分析阶段**\\n基于您的回答，我会进一步提炼以下内容：  \\n1. **核心流程**：  \\n   - 输入 → 检索 → 增强 → 生成 → 输出  \\n2. **关键节点**：  \\n   - 检索算法选择、结果过滤、生成模型调用、输出格式化  \\n3. **业务规则**：  \\n   - 检索结果的阈值、生成模型的超参数、异常处理逻辑  \\n\\n---\\n\\n### **需求验证**\\n在最终确认前，我会与您核对以下内容：  \\n1. 流程图是否覆盖了所有关键业务场景？  \\n2. 是否有遗漏的决策点或分支逻辑？  \\n3. 是否需要补充技术实现细节（如API调用、数据库查询）？  \\n\\n---\\n\\n**示例需求结构化**（假设场景为智能问答）：  \\n```markdown\\n- 流程起点：用户输入问题  \\n- 检索阶段：  \\n  - 使用向量数据库（如FAISS）进行相似度检索  \\n  - 返回Top-5相关文档  \\n- 增强阶段：  \\n  - 将问题与文档拼接为Prompt，调用GPT-4生成答案  \\n- 生成阶段：  \\n  - 输出结构化JSON（含答案、引用来源、置信度）  \\n- 流程终点：返回结果给用户  \\n- 异常处理：  \\n  - 若检索无结果，提示用户“未找到相关内容”  \\n  - 若生成失败，回退到FAQ库  \\n```\\n\\n---\\n\\n请根据您的实际需求补充或修正上述内容，我将为您生成更精准的流程图需求规格！')] role='model'\n",
      "Agent Response: 好的！为了更精准地为您设计RAG（Retrieval-Augmented Generation，检索增强生成）流程图，我需要进一步了解一些关键信息。以下是几个引导性问题，帮助我们明确需求：\n",
      "\n",
      "---\n",
      "\n",
      "### **需求收集阶段**\n",
      "1. **核心场景**  \n",
      "   - 您的RAG流程具体应用于哪个领域？（如智能问答、文档摘要、知识库检索等）  \n",
      "   - 是否有特定的输入/输出要求？（例如用户输入问题，输出结构化答案）\n",
      "\n",
      "2. **流程细节**  \n",
      "   - **检索阶段**：  \n",
      "     - 使用的检索技术是什么？（如向量相似度检索、关键词匹配、BM25等）  \n",
      "     - 检索的数据源是什么？（数据库、文档库、API等）  \n",
      "     - 是否有过滤或排序规则？（如时间、相关性、权重）  \n",
      "   - **增强阶段**：  \n",
      "     - 如何将检索结果与生成模型结合？（如直接拼接、加权融合、多轮迭代）  \n",
      "     - 是否需要人工干预或后处理？（如答案校验、格式化）  \n",
      "   - **生成阶段**：  \n",
      "     - 使用的生成模型是什么？（如GPT-4、LLaMA、自定义模型）  \n",
      "     - 输出格式是否有要求？（如JSON、自然语言、图表）  \n",
      "\n",
      "3. **关键约束**  \n",
      "   - 是否有性能要求？（如响应时间、并发量）  \n",
      "   - 是否有安全或合规性限制？（如数据脱敏、访问控制）  \n",
      "   - 是否有异常处理需求？（如检索失败、生成结果不可用时的回退策略）\n",
      "\n",
      "---\n",
      "\n",
      "### **需求分析阶段**\n",
      "基于您的回答，我会进一步提炼以下内容：  \n",
      "1. **核心流程**：  \n",
      "   - 输入 → 检索 → 增强 → 生成 → 输出  \n",
      "2. **关键节点**：  \n",
      "   - 检索算法选择、结果过滤、生成模型调用、输出格式化  \n",
      "3. **业务规则**：  \n",
      "   - 检索结果的阈值、生成模型的超参数、异常处理逻辑  \n",
      "\n",
      "---\n",
      "\n",
      "### **需求验证**\n",
      "在最终确认前，我会与您核对以下内容：  \n",
      "1. 流程图是否覆盖了所有关键业务场景？  \n",
      "2. 是否有遗漏的决策点或分支逻辑？  \n",
      "3. 是否需要补充技术实现细节（如API调用、数据库查询）？  \n",
      "\n",
      "---\n",
      "\n",
      "**示例需求结构化**（假设场景为智能问答）：  \n",
      "```markdown\n",
      "- 流程起点：用户输入问题  \n",
      "- 检索阶段：  \n",
      "  - 使用向量数据库（如FAISS）进行相似度检索  \n",
      "  - 返回Top-5相关文档  \n",
      "- 增强阶段：  \n",
      "  - 将问题与文档拼接为Prompt，调用GPT-4生成答案  \n",
      "- 生成阶段：  \n",
      "  - 输出结构化JSON（含答案、引用来源、置信度）  \n",
      "- 流程终点：返回结果给用户  \n",
      "- 异常处理：  \n",
      "  - 若检索无结果，提示用户“未找到相关内容”  \n",
      "  - 若生成失败，回退到FAQ库  \n",
      "```\n",
      "\n",
      "---\n",
      "\n",
      "请根据您的实际需求补充或修正上述内容，我将为您生成更精准的流程图需求规格！\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'好的！为了更精准地为您设计RAG（Retrieval-Augmented Generation，检索增强生成）流程图，我需要进一步了解一些关键信息。以下是几个引导性问题，帮助我们明确需求：\\n\\n---\\n\\n### **需求收集阶段**\\n1. **核心场景**  \\n   - 您的RAG流程具体应用于哪个领域？（如智能问答、文档摘要、知识库检索等）  \\n   - 是否有特定的输入/输出要求？（例如用户输入问题，输出结构化答案）\\n\\n2. **流程细节**  \\n   - **检索阶段**：  \\n     - 使用的检索技术是什么？（如向量相似度检索、关键词匹配、BM25等）  \\n     - 检索的数据源是什么？（数据库、文档库、API等）  \\n     - 是否有过滤或排序规则？（如时间、相关性、权重）  \\n   - **增强阶段**：  \\n     - 如何将检索结果与生成模型结合？（如直接拼接、加权融合、多轮迭代）  \\n     - 是否需要人工干预或后处理？（如答案校验、格式化）  \\n   - **生成阶段**：  \\n     - 使用的生成模型是什么？（如GPT-4、LLaMA、自定义模型）  \\n     - 输出格式是否有要求？（如JSON、自然语言、图表）  \\n\\n3. **关键约束**  \\n   - 是否有性能要求？（如响应时间、并发量）  \\n   - 是否有安全或合规性限制？（如数据脱敏、访问控制）  \\n   - 是否有异常处理需求？（如检索失败、生成结果不可用时的回退策略）\\n\\n---\\n\\n### **需求分析阶段**\\n基于您的回答，我会进一步提炼以下内容：  \\n1. **核心流程**：  \\n   - 输入 → 检索 → 增强 → 生成 → 输出  \\n2. **关键节点**：  \\n   - 检索算法选择、结果过滤、生成模型调用、输出格式化  \\n3. **业务规则**：  \\n   - 检索结果的阈值、生成模型的超参数、异常处理逻辑  \\n\\n---\\n\\n### **需求验证**\\n在最终确认前，我会与您核对以下内容：  \\n1. 流程图是否覆盖了所有关键业务场景？  \\n2. 是否有遗漏的决策点或分支逻辑？  \\n3. 是否需要补充技术实现细节（如API调用、数据库查询）？  \\n\\n---\\n\\n**示例需求结构化**（假设场景为智能问答）：  \\n```markdown\\n- 流程起点：用户输入问题  \\n- 检索阶段：  \\n  - 使用向量数据库（如FAISS）进行相似度检索  \\n  - 返回Top-5相关文档  \\n- 增强阶段：  \\n  - 将问题与文档拼接为Prompt，调用GPT-4生成答案  \\n- 生成阶段：  \\n  - 输出结构化JSON（含答案、引用来源、置信度）  \\n- 流程终点：返回结果给用户  \\n- 异常处理：  \\n  - 若检索无结果，提示用户“未找到相关内容”  \\n  - 若生成失败，回退到FAQ库  \\n```\\n\\n---\\n\\n请根据您的实际需求补充或修正上述内容，我将为您生成更精准的流程图需求规格！'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await call_agent_async(\"帮我画一个RAG的流程图\",root_runner, USER_ID, SESSION_ID_BASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User Query: 智能问答，向量相似度检索，API，相关性，加权融合，不需要人工干预，自定义模型，自然语言 没有约束\n",
      "  [事件] 作者：demand_analysis_agent，类型：Event，最终：True，内容：parts=[Part(video_metadata=None, thought=None, inline_data=None, file_data=None, thought_signature=None, code_execution_result=None, executable_code=None, function_call=None, function_response=None, text='非常感谢您提供的详细信息！根据您的描述，我已经对智能问答系统的RAG流程图需求进行了结构化分析。以下是针对您需求的流程图规格说明：\\n\\n---\\n\\n### **RAG流程图需求规格说明**\\n\\n#### **1. 流程起点**\\n- **用户输入**：自然语言形式的问题（例如：“如何申请信用卡？”）。\\n\\n#### **2. 检索阶段**\\n- **向量相似度检索**：\\n  - **输入**：用户问题经过文本向量化处理（如使用BERT、Sentence-BERT等模型生成向量）。\\n  - **检索**：调用向量数据库（如FAISS、Pinecone等）的API，基于向量相似度（如余弦相似度）检索与问题最相关的Top-K文档或知识片段。\\n  - **输出**：返回相关性排序后的文档列表（例如：Top-5文档及其相关性分数）。\\n\\n#### **3. 增强阶段**\\n- **相关性评估与加权融合**：\\n  - **相关性评估**：根据预设的相关性阈值，过滤掉相关性低于阈值的文档（例如：仅保留相关性分数>0.7的文档）。\\n  - **加权融合**：\\n    - 将用户问题与筛选后的文档内容按相关性分数加权拼接（例如：问题占30%，相关性最高的文档占50%，次高占20%）。\\n    - 生成完整的Prompt，供生成模型使用。\\n\\n#### **4. 生成阶段**\\n- **自定义模型调用**：\\n  - **输入**：加权融合后的Prompt。\\n  - **模型**：调用自定义的生成模型（如基于LLaMA、GPT等微调的模型）。\\n  - **输出**：生成自然语言形式的答案（例如：“申请信用卡需要以下步骤：1. 准备身份证明；2. 填写申请表；3. 提交收入证明...”）。\\n\\n#### **5. 流程终点**\\n- **返回结果**：将生成的答案直接返回给用户，无需人工干预。\\n\\n#### **6. 异常处理（可选补充，虽然您提到没有约束，但为完整性考虑）**\\n- **检索无结果**：如果向量相似度检索未返回任何文档，可以回退到预设的FAQ库或通用回复（例如：“未找到相关内容，请尝试其他问题。”）。\\n- **生成失败**：如果生成模型未能生成有效答案，可以返回错误提示或默认回复（例如：“系统繁忙，请稍后再试。”）。\\n\\n---\\n\\n### **流程图关键节点总结**\\n1. **用户输入** → 2. **文本向量化** → 3. **向量相似度检索** → 4. **相关性评估与过滤** → 5. **加权融合** → 6. **自定义模型生成** → 7. **返回答案**。\\n\\n---\\n\\n### **下一步**\\n- 如果您需要，我可以将上述需求规格转化为具体的流程图（例如使用Mermaid语法或Visio格式），以便更直观地展示流程。\\n- 您是否希望对某些环节进行进一步细化（例如加权融合的具体算法、自定义模型的训练细节等）？\\n\\n请确认上述内容是否符合您的预期，我将根据您的反馈进行调整！')] role='model'\n",
      "Agent Response: 非常感谢您提供的详细信息！根据您的描述，我已经对智能问答系统的RAG流程图需求进行了结构化分析。以下是针对您需求的流程图规格说明：\n",
      "\n",
      "---\n",
      "\n",
      "### **RAG流程图需求规格说明**\n",
      "\n",
      "#### **1. 流程起点**\n",
      "- **用户输入**：自然语言形式的问题（例如：“如何申请信用卡？”）。\n",
      "\n",
      "#### **2. 检索阶段**\n",
      "- **向量相似度检索**：\n",
      "  - **输入**：用户问题经过文本向量化处理（如使用BERT、Sentence-BERT等模型生成向量）。\n",
      "  - **检索**：调用向量数据库（如FAISS、Pinecone等）的API，基于向量相似度（如余弦相似度）检索与问题最相关的Top-K文档或知识片段。\n",
      "  - **输出**：返回相关性排序后的文档列表（例如：Top-5文档及其相关性分数）。\n",
      "\n",
      "#### **3. 增强阶段**\n",
      "- **相关性评估与加权融合**：\n",
      "  - **相关性评估**：根据预设的相关性阈值，过滤掉相关性低于阈值的文档（例如：仅保留相关性分数>0.7的文档）。\n",
      "  - **加权融合**：\n",
      "    - 将用户问题与筛选后的文档内容按相关性分数加权拼接（例如：问题占30%，相关性最高的文档占50%，次高占20%）。\n",
      "    - 生成完整的Prompt，供生成模型使用。\n",
      "\n",
      "#### **4. 生成阶段**\n",
      "- **自定义模型调用**：\n",
      "  - **输入**：加权融合后的Prompt。\n",
      "  - **模型**：调用自定义的生成模型（如基于LLaMA、GPT等微调的模型）。\n",
      "  - **输出**：生成自然语言形式的答案（例如：“申请信用卡需要以下步骤：1. 准备身份证明；2. 填写申请表；3. 提交收入证明...”）。\n",
      "\n",
      "#### **5. 流程终点**\n",
      "- **返回结果**：将生成的答案直接返回给用户，无需人工干预。\n",
      "\n",
      "#### **6. 异常处理（可选补充，虽然您提到没有约束，但为完整性考虑）**\n",
      "- **检索无结果**：如果向量相似度检索未返回任何文档，可以回退到预设的FAQ库或通用回复（例如：“未找到相关内容，请尝试其他问题。”）。\n",
      "- **生成失败**：如果生成模型未能生成有效答案，可以返回错误提示或默认回复（例如：“系统繁忙，请稍后再试。”）。\n",
      "\n",
      "---\n",
      "\n",
      "### **流程图关键节点总结**\n",
      "1. **用户输入** → 2. **文本向量化** → 3. **向量相似度检索** → 4. **相关性评估与过滤** → 5. **加权融合** → 6. **自定义模型生成** → 7. **返回答案**。\n",
      "\n",
      "---\n",
      "\n",
      "### **下一步**\n",
      "- 如果您需要，我可以将上述需求规格转化为具体的流程图（例如使用Mermaid语法或Visio格式），以便更直观地展示流程。\n",
      "- 您是否希望对某些环节进行进一步细化（例如加权融合的具体算法、自定义模型的训练细节等）？\n",
      "\n",
      "请确认上述内容是否符合您的预期，我将根据您的反馈进行调整！\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'非常感谢您提供的详细信息！根据您的描述，我已经对智能问答系统的RAG流程图需求进行了结构化分析。以下是针对您需求的流程图规格说明：\\n\\n---\\n\\n### **RAG流程图需求规格说明**\\n\\n#### **1. 流程起点**\\n- **用户输入**：自然语言形式的问题（例如：“如何申请信用卡？”）。\\n\\n#### **2. 检索阶段**\\n- **向量相似度检索**：\\n  - **输入**：用户问题经过文本向量化处理（如使用BERT、Sentence-BERT等模型生成向量）。\\n  - **检索**：调用向量数据库（如FAISS、Pinecone等）的API，基于向量相似度（如余弦相似度）检索与问题最相关的Top-K文档或知识片段。\\n  - **输出**：返回相关性排序后的文档列表（例如：Top-5文档及其相关性分数）。\\n\\n#### **3. 增强阶段**\\n- **相关性评估与加权融合**：\\n  - **相关性评估**：根据预设的相关性阈值，过滤掉相关性低于阈值的文档（例如：仅保留相关性分数>0.7的文档）。\\n  - **加权融合**：\\n    - 将用户问题与筛选后的文档内容按相关性分数加权拼接（例如：问题占30%，相关性最高的文档占50%，次高占20%）。\\n    - 生成完整的Prompt，供生成模型使用。\\n\\n#### **4. 生成阶段**\\n- **自定义模型调用**：\\n  - **输入**：加权融合后的Prompt。\\n  - **模型**：调用自定义的生成模型（如基于LLaMA、GPT等微调的模型）。\\n  - **输出**：生成自然语言形式的答案（例如：“申请信用卡需要以下步骤：1. 准备身份证明；2. 填写申请表；3. 提交收入证明...”）。\\n\\n#### **5. 流程终点**\\n- **返回结果**：将生成的答案直接返回给用户，无需人工干预。\\n\\n#### **6. 异常处理（可选补充，虽然您提到没有约束，但为完整性考虑）**\\n- **检索无结果**：如果向量相似度检索未返回任何文档，可以回退到预设的FAQ库或通用回复（例如：“未找到相关内容，请尝试其他问题。”）。\\n- **生成失败**：如果生成模型未能生成有效答案，可以返回错误提示或默认回复（例如：“系统繁忙，请稍后再试。”）。\\n\\n---\\n\\n### **流程图关键节点总结**\\n1. **用户输入** → 2. **文本向量化** → 3. **向量相似度检索** → 4. **相关性评估与过滤** → 5. **加权融合** → 6. **自定义模型生成** → 7. **返回答案**。\\n\\n---\\n\\n### **下一步**\\n- 如果您需要，我可以将上述需求规格转化为具体的流程图（例如使用Mermaid语法或Visio格式），以便更直观地展示流程。\\n- 您是否希望对某些环节进行进一步细化（例如加权融合的具体算法、自定义模型的训练细节等）？\\n\\n请确认上述内容是否符合您的预期，我将根据您的反馈进行调整！'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await call_agent_async(\"智能问答，向量相似度检索，API，相关性，加权融合，不需要人工干预，自定义模型，自然语言 没有约束\",root_runner, USER_ID, SESSION_ID_BASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User Query: 生成流程图吧\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unclosed client session\n",
      "client_session: <aiohttp.client.ClientSession object at 0x0000025328BC34D0>\n"
     ]
    },
    {
     "ename": "CancelledError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mCancelledError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m call_agent_async(\u001b[33m\"\u001b[39m\u001b[33m生成流程图吧\u001b[39m\u001b[33m\"\u001b[39m,root_runner, USER_ID, SESSION_ID_BASE)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 12\u001b[39m, in \u001b[36mcall_agent_async\u001b[39m\u001b[34m(query, runner, user_id, session_id)\u001b[39m\n\u001b[32m      8\u001b[39m final_response_text = \u001b[33m\"\u001b[39m\u001b[33m智能体没有产生最终响应。\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;66;03m# 默认值\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# 关键概念：run_async 执行智能体逻辑并产生事件。\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# 我们遍历事件以找到最终答案。\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m runner.run_async(user_id=user_id, session_id=session_id, new_message=content):\n\u001b[32m     13\u001b[39m     \u001b[38;5;66;03m# 你可以取消注释下面的行以查看执行期间的*所有*事件\u001b[39;00m\n\u001b[32m     14\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m  [事件] 作者：\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent.author\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m，类型：\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(event).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m，最终：\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent.is_final_response()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m，内容：\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent.content\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     16\u001b[39m     \u001b[38;5;66;03m# 关键概念：is_final_response() 标记轮次的结束消息。\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Software\\anaconda3\\envs\\adk\\Lib\\site-packages\\google\\adk\\runners.py:197\u001b[39m, in \u001b[36mRunner.run_async\u001b[39m\u001b[34m(self, user_id, session_id, new_message, run_config)\u001b[39m\n\u001b[32m    189\u001b[39m   \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._append_new_message_to_session(\n\u001b[32m    190\u001b[39m       session,\n\u001b[32m    191\u001b[39m       new_message,\n\u001b[32m    192\u001b[39m       invocation_context,\n\u001b[32m    193\u001b[39m       run_config.save_input_blobs_as_artifacts,\n\u001b[32m    194\u001b[39m   )\n\u001b[32m    196\u001b[39m invocation_context.agent = \u001b[38;5;28mself\u001b[39m._find_agent_to_run(session, root_agent)\n\u001b[32m--> \u001b[39m\u001b[32m197\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m invocation_context.agent.run_async(invocation_context):\n\u001b[32m    198\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m event.partial:\n\u001b[32m    199\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.session_service.append_event(session=session, event=event)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Software\\anaconda3\\envs\\adk\\Lib\\site-packages\\google\\adk\\agents\\base_agent.py:147\u001b[39m, in \u001b[36mBaseAgent.run_async\u001b[39m\u001b[34m(self, parent_context)\u001b[39m\n\u001b[32m    144\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ctx.end_invocation:\n\u001b[32m    145\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m147\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._run_async_impl(ctx):\n\u001b[32m    148\u001b[39m   \u001b[38;5;28;01myield\u001b[39;00m event\n\u001b[32m    150\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ctx.end_invocation:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Software\\anaconda3\\envs\\adk\\Lib\\site-packages\\google\\adk\\agents\\sequential_agent.py:37\u001b[39m, in \u001b[36mSequentialAgent._run_async_impl\u001b[39m\u001b[34m(self, ctx)\u001b[39m\n\u001b[32m     32\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m     33\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_run_async_impl\u001b[39m(\n\u001b[32m     34\u001b[39m     \u001b[38;5;28mself\u001b[39m, ctx: InvocationContext\n\u001b[32m     35\u001b[39m ) -> AsyncGenerator[Event, \u001b[38;5;28;01mNone\u001b[39;00m]:\n\u001b[32m     36\u001b[39m   \u001b[38;5;28;01mfor\u001b[39;00m sub_agent \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.sub_agents:\n\u001b[32m---> \u001b[39m\u001b[32m37\u001b[39m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m sub_agent.run_async(ctx):\n\u001b[32m     38\u001b[39m       \u001b[38;5;28;01myield\u001b[39;00m event\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Software\\anaconda3\\envs\\adk\\Lib\\site-packages\\google\\adk\\agents\\base_agent.py:147\u001b[39m, in \u001b[36mBaseAgent.run_async\u001b[39m\u001b[34m(self, parent_context)\u001b[39m\n\u001b[32m    144\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ctx.end_invocation:\n\u001b[32m    145\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m147\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._run_async_impl(ctx):\n\u001b[32m    148\u001b[39m   \u001b[38;5;28;01myield\u001b[39;00m event\n\u001b[32m    150\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ctx.end_invocation:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Software\\anaconda3\\envs\\adk\\Lib\\site-packages\\google\\adk\\agents\\llm_agent.py:278\u001b[39m, in \u001b[36mLlmAgent._run_async_impl\u001b[39m\u001b[34m(self, ctx)\u001b[39m\n\u001b[32m    274\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    275\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_run_async_impl\u001b[39m(\n\u001b[32m    276\u001b[39m     \u001b[38;5;28mself\u001b[39m, ctx: InvocationContext\n\u001b[32m    277\u001b[39m ) -> AsyncGenerator[Event, \u001b[38;5;28;01mNone\u001b[39;00m]:\n\u001b[32m--> \u001b[39m\u001b[32m278\u001b[39m   \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._llm_flow.run_async(ctx):\n\u001b[32m    279\u001b[39m     \u001b[38;5;28mself\u001b[39m.__maybe_save_output_to_state(event)\n\u001b[32m    280\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m event\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Software\\anaconda3\\envs\\adk\\Lib\\site-packages\\google\\adk\\flows\\llm_flows\\base_llm_flow.py:282\u001b[39m, in \u001b[36mBaseLlmFlow.run_async\u001b[39m\u001b[34m(self, invocation_context)\u001b[39m\n\u001b[32m    280\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    281\u001b[39m   last_event = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m282\u001b[39m   \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._run_one_step_async(invocation_context):\n\u001b[32m    283\u001b[39m     last_event = event\n\u001b[32m    284\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m event\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Software\\anaconda3\\envs\\adk\\Lib\\site-packages\\google\\adk\\flows\\llm_flows\\base_llm_flow.py:314\u001b[39m, in \u001b[36mBaseLlmFlow._run_one_step_async\u001b[39m\u001b[34m(self, invocation_context)\u001b[39m\n\u001b[32m    307\u001b[39m \u001b[38;5;66;03m# Calls the LLM.\u001b[39;00m\n\u001b[32m    308\u001b[39m model_response_event = Event(\n\u001b[32m    309\u001b[39m     \u001b[38;5;28mid\u001b[39m=Event.new_id(),\n\u001b[32m    310\u001b[39m     invocation_id=invocation_context.invocation_id,\n\u001b[32m    311\u001b[39m     author=invocation_context.agent.name,\n\u001b[32m    312\u001b[39m     branch=invocation_context.branch,\n\u001b[32m    313\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m314\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m llm_response \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call_llm_async(\n\u001b[32m    315\u001b[39m     invocation_context, llm_request, model_response_event\n\u001b[32m    316\u001b[39m ):\n\u001b[32m    317\u001b[39m   \u001b[38;5;66;03m# Postprocess after calling the LLM.\u001b[39;00m\n\u001b[32m    318\u001b[39m   \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._postprocess_async(\n\u001b[32m    319\u001b[39m       invocation_context, llm_request, llm_response, model_response_event\n\u001b[32m    320\u001b[39m   ):\n\u001b[32m    321\u001b[39m     \u001b[38;5;66;03m# Update the mutable event id to avoid conflict\u001b[39;00m\n\u001b[32m    322\u001b[39m     model_response_event.id = Event.new_id()\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Software\\anaconda3\\envs\\adk\\Lib\\site-packages\\google\\adk\\flows\\llm_flows\\base_llm_flow.py:539\u001b[39m, in \u001b[36mBaseLlmFlow._call_llm_async\u001b[39m\u001b[34m(self, invocation_context, llm_request, model_response_event)\u001b[39m\n\u001b[32m    534\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    535\u001b[39m   \u001b[38;5;66;03m# Check if we can make this llm call or not. If the current call pushes\u001b[39;00m\n\u001b[32m    536\u001b[39m   \u001b[38;5;66;03m# the counter beyond the max set value, then the execution is stopped\u001b[39;00m\n\u001b[32m    537\u001b[39m   \u001b[38;5;66;03m# right here, and exception is thrown.\u001b[39;00m\n\u001b[32m    538\u001b[39m   invocation_context.increment_llm_call_count()\n\u001b[32m--> \u001b[39m\u001b[32m539\u001b[39m   \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m llm_response \u001b[38;5;129;01min\u001b[39;00m llm.generate_content_async(\n\u001b[32m    540\u001b[39m       llm_request,\n\u001b[32m    541\u001b[39m       stream=invocation_context.run_config.streaming_mode\n\u001b[32m    542\u001b[39m       == StreamingMode.SSE,\n\u001b[32m    543\u001b[39m   ):\n\u001b[32m    544\u001b[39m     trace_call_llm(\n\u001b[32m    545\u001b[39m         invocation_context,\n\u001b[32m    546\u001b[39m         model_response_event.id,\n\u001b[32m    547\u001b[39m         llm_request,\n\u001b[32m    548\u001b[39m         llm_response,\n\u001b[32m    549\u001b[39m     )\n\u001b[32m    550\u001b[39m     \u001b[38;5;66;03m# Runs after_model_callback if it exists.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Software\\anaconda3\\envs\\adk\\Lib\\site-packages\\google\\adk\\models\\lite_llm.py:769\u001b[39m, in \u001b[36mLiteLlm.generate_content_async\u001b[39m\u001b[34m(self, llm_request, stream)\u001b[39m\n\u001b[32m    766\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m aggregated_llm_response_with_tool_call\n\u001b[32m    768\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m769\u001b[39m   response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.llm_client.acompletion(**completion_args)\n\u001b[32m    770\u001b[39m   \u001b[38;5;28;01myield\u001b[39;00m _model_response_to_generate_content_response(response)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Software\\anaconda3\\envs\\adk\\Lib\\site-packages\\google\\adk\\models\\lite_llm.py:97\u001b[39m, in \u001b[36mLiteLLMClient.acompletion\u001b[39m\u001b[34m(self, model, messages, tools, **kwargs)\u001b[39m\n\u001b[32m     82\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34macompletion\u001b[39m(\n\u001b[32m     83\u001b[39m     \u001b[38;5;28mself\u001b[39m, model, messages, tools, **kwargs\n\u001b[32m     84\u001b[39m ) -> Union[ModelResponse, CustomStreamWrapper]:\n\u001b[32m     85\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Asynchronously calls acompletion.\u001b[39;00m\n\u001b[32m     86\u001b[39m \n\u001b[32m     87\u001b[39m \u001b[33;03m  Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     94\u001b[39m \u001b[33;03m    The model response as a message.\u001b[39;00m\n\u001b[32m     95\u001b[39m \u001b[33;03m  \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m97\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m acompletion(\n\u001b[32m     98\u001b[39m       model=model,\n\u001b[32m     99\u001b[39m       messages=messages,\n\u001b[32m    100\u001b[39m       tools=tools,\n\u001b[32m    101\u001b[39m       **kwargs,\n\u001b[32m    102\u001b[39m   )\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Software\\anaconda3\\envs\\adk\\Lib\\site-packages\\litellm\\utils.py:1355\u001b[39m, in \u001b[36mclient.<locals>.wrapper_async\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m   1352\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _caching_handler_response.final_embedding_cached_response\n\u001b[32m   1354\u001b[39m \u001b[38;5;66;03m# MODEL CALL\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1355\u001b[39m result = \u001b[38;5;28;01mawait\u001b[39;00m original_function(*args, **kwargs)\n\u001b[32m   1356\u001b[39m end_time = datetime.datetime.now()\n\u001b[32m   1357\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m kwargs \u001b[38;5;129;01mand\u001b[39;00m kwargs[\u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Software\\anaconda3\\envs\\adk\\Lib\\site-packages\\litellm\\main.py:524\u001b[39m, in \u001b[36macompletion\u001b[39m\u001b[34m(model, messages, functions, function_call, timeout, temperature, top_p, n, stream, stream_options, stop, max_tokens, max_completion_tokens, modalities, prediction, audio, presence_penalty, frequency_penalty, logit_bias, user, response_format, seed, tools, tool_choice, parallel_tool_calls, logprobs, top_logprobs, deployment_id, reasoning_effort, base_url, api_version, api_key, model_list, extra_headers, thinking, web_search_options, **kwargs)\u001b[39m\n\u001b[32m    522\u001b[39m     response = init_response\n\u001b[32m    523\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m asyncio.iscoroutine(init_response):\n\u001b[32m--> \u001b[39m\u001b[32m524\u001b[39m     response = \u001b[38;5;28;01mawait\u001b[39;00m init_response\n\u001b[32m    525\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    526\u001b[39m     response = init_response  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Software\\anaconda3\\envs\\adk\\Lib\\site-packages\\litellm\\llms\\openai\\openai.py:801\u001b[39m, in \u001b[36mOpenAIChatCompletion.acompletion\u001b[39m\u001b[34m(self, messages, optional_params, litellm_params, provider_config, model, model_response, logging_obj, timeout, api_key, api_base, api_version, organization, client, max_retries, headers, drop_params, stream_options, fake_stream)\u001b[39m\n\u001b[32m    787\u001b[39m \u001b[38;5;66;03m## LOGGING\u001b[39;00m\n\u001b[32m    788\u001b[39m logging_obj.pre_call(\n\u001b[32m    789\u001b[39m     \u001b[38;5;28minput\u001b[39m=data[\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m    790\u001b[39m     api_key=openai_aclient.api_key,\n\u001b[32m   (...)\u001b[39m\u001b[32m    798\u001b[39m     },\n\u001b[32m    799\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m801\u001b[39m headers, response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.make_openai_chat_completion_request(\n\u001b[32m    802\u001b[39m     openai_aclient=openai_aclient,\n\u001b[32m    803\u001b[39m     data=data,\n\u001b[32m    804\u001b[39m     timeout=timeout,\n\u001b[32m    805\u001b[39m     logging_obj=logging_obj,\n\u001b[32m    806\u001b[39m )\n\u001b[32m    807\u001b[39m stringified_response = response.model_dump()\n\u001b[32m    809\u001b[39m logging_obj.post_call(\n\u001b[32m    810\u001b[39m     \u001b[38;5;28minput\u001b[39m=data[\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m    811\u001b[39m     api_key=api_key,\n\u001b[32m    812\u001b[39m     original_response=stringified_response,\n\u001b[32m    813\u001b[39m     additional_args={\u001b[33m\"\u001b[39m\u001b[33mcomplete_input_dict\u001b[39m\u001b[33m\"\u001b[39m: data},\n\u001b[32m    814\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Software\\anaconda3\\envs\\adk\\Lib\\site-packages\\litellm\\litellm_core_utils\\logging_utils.py:135\u001b[39m, in \u001b[36mtrack_llm_api_timing.<locals>.decorator.<locals>.async_wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    133\u001b[39m start_time = datetime.now()\n\u001b[32m    134\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m135\u001b[39m     result = \u001b[38;5;28;01mawait\u001b[39;00m func(*args, **kwargs)\n\u001b[32m    136\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[32m    137\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Software\\anaconda3\\envs\\adk\\Lib\\site-packages\\litellm\\llms\\openai\\openai.py:418\u001b[39m, in \u001b[36mOpenAIChatCompletion.make_openai_chat_completion_request\u001b[39m\u001b[34m(self, openai_aclient, data, timeout, logging_obj)\u001b[39m\n\u001b[32m    415\u001b[39m start_time = time.time()\n\u001b[32m    416\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    417\u001b[39m     raw_response = (\n\u001b[32m--> \u001b[39m\u001b[32m418\u001b[39m         \u001b[38;5;28;01mawait\u001b[39;00m openai_aclient.chat.completions.with_raw_response.create(\n\u001b[32m    419\u001b[39m             **data, timeout=timeout\n\u001b[32m    420\u001b[39m         )\n\u001b[32m    421\u001b[39m     )\n\u001b[32m    422\u001b[39m     end_time = time.time()\n\u001b[32m    424\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(raw_response, \u001b[33m\"\u001b[39m\u001b[33mheaders\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Software\\anaconda3\\envs\\adk\\Lib\\site-packages\\openai\\_legacy_response.py:381\u001b[39m, in \u001b[36masync_to_raw_response_wrapper.<locals>.wrapped\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    377\u001b[39m extra_headers[RAW_RESPONSE_HEADER] = \u001b[33m\"\u001b[39m\u001b[33mtrue\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    379\u001b[39m kwargs[\u001b[33m\"\u001b[39m\u001b[33mextra_headers\u001b[39m\u001b[33m\"\u001b[39m] = extra_headers\n\u001b[32m--> \u001b[39m\u001b[32m381\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m cast(LegacyAPIResponse[R], \u001b[38;5;28;01mawait\u001b[39;00m func(*args, **kwargs))\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Software\\anaconda3\\envs\\adk\\Lib\\site-packages\\openai\\resources\\chat\\completions\\completions.py:2028\u001b[39m, in \u001b[36mAsyncCompletions.create\u001b[39m\u001b[34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m   1985\u001b[39m \u001b[38;5;129m@required_args\u001b[39m([\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m], [\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m   1986\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate\u001b[39m(\n\u001b[32m   1987\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   2025\u001b[39m     timeout: \u001b[38;5;28mfloat\u001b[39m | httpx.Timeout | \u001b[38;5;28;01mNone\u001b[39;00m | NotGiven = NOT_GIVEN,\n\u001b[32m   2026\u001b[39m ) -> ChatCompletion | AsyncStream[ChatCompletionChunk]:\n\u001b[32m   2027\u001b[39m     validate_response_format(response_format)\n\u001b[32m-> \u001b[39m\u001b[32m2028\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._post(\n\u001b[32m   2029\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m/chat/completions\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   2030\u001b[39m         body=\u001b[38;5;28;01mawait\u001b[39;00m async_maybe_transform(\n\u001b[32m   2031\u001b[39m             {\n\u001b[32m   2032\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m: messages,\n\u001b[32m   2033\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m: model,\n\u001b[32m   2034\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33maudio\u001b[39m\u001b[33m\"\u001b[39m: audio,\n\u001b[32m   2035\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mfrequency_penalty\u001b[39m\u001b[33m\"\u001b[39m: frequency_penalty,\n\u001b[32m   2036\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mfunction_call\u001b[39m\u001b[33m\"\u001b[39m: function_call,\n\u001b[32m   2037\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mfunctions\u001b[39m\u001b[33m\"\u001b[39m: functions,\n\u001b[32m   2038\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mlogit_bias\u001b[39m\u001b[33m\"\u001b[39m: logit_bias,\n\u001b[32m   2039\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mlogprobs\u001b[39m\u001b[33m\"\u001b[39m: logprobs,\n\u001b[32m   2040\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mmax_completion_tokens\u001b[39m\u001b[33m\"\u001b[39m: max_completion_tokens,\n\u001b[32m   2041\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mmax_tokens\u001b[39m\u001b[33m\"\u001b[39m: max_tokens,\n\u001b[32m   2042\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mmetadata\u001b[39m\u001b[33m\"\u001b[39m: metadata,\n\u001b[32m   2043\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mmodalities\u001b[39m\u001b[33m\"\u001b[39m: modalities,\n\u001b[32m   2044\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mn\u001b[39m\u001b[33m\"\u001b[39m: n,\n\u001b[32m   2045\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mparallel_tool_calls\u001b[39m\u001b[33m\"\u001b[39m: parallel_tool_calls,\n\u001b[32m   2046\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mprediction\u001b[39m\u001b[33m\"\u001b[39m: prediction,\n\u001b[32m   2047\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mpresence_penalty\u001b[39m\u001b[33m\"\u001b[39m: presence_penalty,\n\u001b[32m   2048\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mreasoning_effort\u001b[39m\u001b[33m\"\u001b[39m: reasoning_effort,\n\u001b[32m   2049\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mresponse_format\u001b[39m\u001b[33m\"\u001b[39m: response_format,\n\u001b[32m   2050\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mseed\u001b[39m\u001b[33m\"\u001b[39m: seed,\n\u001b[32m   2051\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mservice_tier\u001b[39m\u001b[33m\"\u001b[39m: service_tier,\n\u001b[32m   2052\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mstop\u001b[39m\u001b[33m\"\u001b[39m: stop,\n\u001b[32m   2053\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mstore\u001b[39m\u001b[33m\"\u001b[39m: store,\n\u001b[32m   2054\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m: stream,\n\u001b[32m   2055\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mstream_options\u001b[39m\u001b[33m\"\u001b[39m: stream_options,\n\u001b[32m   2056\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mtemperature\u001b[39m\u001b[33m\"\u001b[39m: temperature,\n\u001b[32m   2057\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mtool_choice\u001b[39m\u001b[33m\"\u001b[39m: tool_choice,\n\u001b[32m   2058\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mtools\u001b[39m\u001b[33m\"\u001b[39m: tools,\n\u001b[32m   2059\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mtop_logprobs\u001b[39m\u001b[33m\"\u001b[39m: top_logprobs,\n\u001b[32m   2060\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mtop_p\u001b[39m\u001b[33m\"\u001b[39m: top_p,\n\u001b[32m   2061\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33muser\u001b[39m\u001b[33m\"\u001b[39m: user,\n\u001b[32m   2062\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mweb_search_options\u001b[39m\u001b[33m\"\u001b[39m: web_search_options,\n\u001b[32m   2063\u001b[39m             },\n\u001b[32m   2064\u001b[39m             completion_create_params.CompletionCreateParamsStreaming\n\u001b[32m   2065\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m stream\n\u001b[32m   2066\u001b[39m             \u001b[38;5;28;01melse\u001b[39;00m completion_create_params.CompletionCreateParamsNonStreaming,\n\u001b[32m   2067\u001b[39m         ),\n\u001b[32m   2068\u001b[39m         options=make_request_options(\n\u001b[32m   2069\u001b[39m             extra_headers=extra_headers, extra_query=extra_query, extra_body=extra_body, timeout=timeout\n\u001b[32m   2070\u001b[39m         ),\n\u001b[32m   2071\u001b[39m         cast_to=ChatCompletion,\n\u001b[32m   2072\u001b[39m         stream=stream \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m   2073\u001b[39m         stream_cls=AsyncStream[ChatCompletionChunk],\n\u001b[32m   2074\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Software\\anaconda3\\envs\\adk\\Lib\\site-packages\\openai\\_base_client.py:1742\u001b[39m, in \u001b[36mAsyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, files, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1728\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1729\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1730\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1737\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_AsyncStreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1738\u001b[39m ) -> ResponseT | _AsyncStreamT:\n\u001b[32m   1739\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1740\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=\u001b[38;5;28;01mawait\u001b[39;00m async_to_httpx_files(files), **options\n\u001b[32m   1741\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1742\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Software\\anaconda3\\envs\\adk\\Lib\\site-packages\\openai\\_base_client.py:1484\u001b[39m, in \u001b[36mAsyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1482\u001b[39m response = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1483\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1484\u001b[39m     response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._client.send(\n\u001b[32m   1485\u001b[39m         request,\n\u001b[32m   1486\u001b[39m         stream=stream \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._should_stream_response_body(request=request),\n\u001b[32m   1487\u001b[39m         **kwargs,\n\u001b[32m   1488\u001b[39m     )\n\u001b[32m   1489\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m httpx.TimeoutException \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m   1490\u001b[39m     log.debug(\u001b[33m\"\u001b[39m\u001b[33mEncountered httpx.TimeoutException\u001b[39m\u001b[33m\"\u001b[39m, exc_info=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Software\\anaconda3\\envs\\adk\\Lib\\site-packages\\httpx\\_client.py:1629\u001b[39m, in \u001b[36mAsyncClient.send\u001b[39m\u001b[34m(self, request, stream, auth, follow_redirects)\u001b[39m\n\u001b[32m   1625\u001b[39m \u001b[38;5;28mself\u001b[39m._set_timeout(request)\n\u001b[32m   1627\u001b[39m auth = \u001b[38;5;28mself\u001b[39m._build_request_auth(request, auth)\n\u001b[32m-> \u001b[39m\u001b[32m1629\u001b[39m response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._send_handling_auth(\n\u001b[32m   1630\u001b[39m     request,\n\u001b[32m   1631\u001b[39m     auth=auth,\n\u001b[32m   1632\u001b[39m     follow_redirects=follow_redirects,\n\u001b[32m   1633\u001b[39m     history=[],\n\u001b[32m   1634\u001b[39m )\n\u001b[32m   1635\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1636\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Software\\anaconda3\\envs\\adk\\Lib\\site-packages\\httpx\\_client.py:1657\u001b[39m, in \u001b[36mAsyncClient._send_handling_auth\u001b[39m\u001b[34m(self, request, auth, follow_redirects, history)\u001b[39m\n\u001b[32m   1654\u001b[39m request = \u001b[38;5;28;01mawait\u001b[39;00m auth_flow.\u001b[34m__anext__\u001b[39m()\n\u001b[32m   1656\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1657\u001b[39m     response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._send_handling_redirects(\n\u001b[32m   1658\u001b[39m         request,\n\u001b[32m   1659\u001b[39m         follow_redirects=follow_redirects,\n\u001b[32m   1660\u001b[39m         history=history,\n\u001b[32m   1661\u001b[39m     )\n\u001b[32m   1662\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1663\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Software\\anaconda3\\envs\\adk\\Lib\\site-packages\\httpx\\_client.py:1694\u001b[39m, in \u001b[36mAsyncClient._send_handling_redirects\u001b[39m\u001b[34m(self, request, follow_redirects, history)\u001b[39m\n\u001b[32m   1691\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._event_hooks[\u001b[33m\"\u001b[39m\u001b[33mrequest\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m   1692\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m hook(request)\n\u001b[32m-> \u001b[39m\u001b[32m1694\u001b[39m response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._send_single_request(request)\n\u001b[32m   1695\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1696\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._event_hooks[\u001b[33m\"\u001b[39m\u001b[33mresponse\u001b[39m\u001b[33m\"\u001b[39m]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Software\\anaconda3\\envs\\adk\\Lib\\site-packages\\httpx\\_client.py:1730\u001b[39m, in \u001b[36mAsyncClient._send_single_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m   1725\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m   1726\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAttempted to send an sync request with an AsyncClient instance.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1727\u001b[39m     )\n\u001b[32m   1729\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request=request):\n\u001b[32m-> \u001b[39m\u001b[32m1730\u001b[39m     response = \u001b[38;5;28;01mawait\u001b[39;00m transport.handle_async_request(request)\n\u001b[32m   1732\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response.stream, AsyncByteStream)\n\u001b[32m   1733\u001b[39m response.request = request\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Software\\anaconda3\\envs\\adk\\Lib\\site-packages\\litellm\\llms\\custom_httpx\\aiohttp_transport.py:207\u001b[39m, in \u001b[36mLiteLLMAiohttpTransport.handle_async_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    204\u001b[39m         data = request.stream  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[32m    205\u001b[39m         request.headers.pop(\u001b[33m\"\u001b[39m\u001b[33mtransfer-encoding\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)  \u001b[38;5;66;03m# handled by aiohttp\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m207\u001b[39m     response = \u001b[38;5;28;01mawait\u001b[39;00m client_session.request(\n\u001b[32m    208\u001b[39m         method=request.method,\n\u001b[32m    209\u001b[39m         url=YarlURL(\u001b[38;5;28mstr\u001b[39m(request.url), encoded=\u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[32m    210\u001b[39m         headers=request.headers,\n\u001b[32m    211\u001b[39m         data=data,\n\u001b[32m    212\u001b[39m         allow_redirects=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    213\u001b[39m         auto_decompress=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    214\u001b[39m         timeout=ClientTimeout(\n\u001b[32m    215\u001b[39m             sock_connect=timeout.get(\u001b[33m\"\u001b[39m\u001b[33mconnect\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m    216\u001b[39m             sock_read=timeout.get(\u001b[33m\"\u001b[39m\u001b[33mread\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m    217\u001b[39m             connect=timeout.get(\u001b[33m\"\u001b[39m\u001b[33mpool\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m    218\u001b[39m         ),\n\u001b[32m    219\u001b[39m         server_hostname=sni_hostname,\n\u001b[32m    220\u001b[39m     ).\u001b[34m__aenter__\u001b[39m()\n\u001b[32m    222\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m httpx.Response(\n\u001b[32m    223\u001b[39m     status_code=response.status,\n\u001b[32m    224\u001b[39m     headers=response.headers,\n\u001b[32m    225\u001b[39m     content=AiohttpResponseStream(response),\n\u001b[32m    226\u001b[39m     request=request,\n\u001b[32m    227\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Software\\anaconda3\\envs\\adk\\Lib\\site-packages\\aiohttp\\client.py:1425\u001b[39m, in \u001b[36m_BaseRequestContextManager.__aenter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1424\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__aenter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> _RetType:\n\u001b[32m-> \u001b[39m\u001b[32m1425\u001b[39m     \u001b[38;5;28mself\u001b[39m._resp: _RetType = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._coro\n\u001b[32m   1426\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._resp.\u001b[34m__aenter__\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Software\\anaconda3\\envs\\adk\\Lib\\site-packages\\aiohttp\\client.py:730\u001b[39m, in \u001b[36mClientSession._request\u001b[39m\u001b[34m(self, method, str_or_url, params, data, json, cookies, headers, skip_auto_headers, auth, allow_redirects, max_redirects, compress, chunked, expect100, raise_for_status, read_until_eof, proxy, proxy_auth, timeout, verify_ssl, fingerprint, ssl_context, ssl, server_hostname, proxy_headers, trace_request_ctx, read_bufsize, auto_decompress, max_line_size, max_field_size)\u001b[39m\n\u001b[32m    728\u001b[39m resp = \u001b[38;5;28;01mawait\u001b[39;00m req.send(conn)\n\u001b[32m    729\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m730\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m resp.start(conn)\n\u001b[32m    731\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:\n\u001b[32m    732\u001b[39m     resp.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Software\\anaconda3\\envs\\adk\\Lib\\site-packages\\aiohttp\\client_reqrep.py:1059\u001b[39m, in \u001b[36mClientResponse.start\u001b[39m\u001b[34m(self, connection)\u001b[39m\n\u001b[32m   1057\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1058\u001b[39m     protocol = \u001b[38;5;28mself\u001b[39m._protocol\n\u001b[32m-> \u001b[39m\u001b[32m1059\u001b[39m     message, payload = \u001b[38;5;28;01mawait\u001b[39;00m protocol.read()  \u001b[38;5;66;03m# type: ignore[union-attr]\u001b[39;00m\n\u001b[32m   1060\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m http.HttpProcessingError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m   1061\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ClientResponseError(\n\u001b[32m   1062\u001b[39m         \u001b[38;5;28mself\u001b[39m.request_info,\n\u001b[32m   1063\u001b[39m         \u001b[38;5;28mself\u001b[39m.history,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1066\u001b[39m         headers=exc.headers,\n\u001b[32m   1067\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mexc\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Software\\anaconda3\\envs\\adk\\Lib\\site-packages\\aiohttp\\streams.py:672\u001b[39m, in \u001b[36mDataQueue.read\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    670\u001b[39m \u001b[38;5;28mself\u001b[39m._waiter = \u001b[38;5;28mself\u001b[39m._loop.create_future()\n\u001b[32m    671\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m672\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._waiter\n\u001b[32m    673\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (asyncio.CancelledError, asyncio.TimeoutError):\n\u001b[32m    674\u001b[39m     \u001b[38;5;28mself\u001b[39m._waiter = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[31mCancelledError\u001b[39m: "
     ]
    }
   ],
   "source": [
    "await call_agent_async(\"生成流程图吧\",root_runner, USER_ID, SESSION_ID_BASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "你好！我是一个大型语言模型，由 Google 训练。\n"
     ]
    }
   ],
   "source": [
    "from google import genai\n",
    "\n",
    "client = genai.Client(api_key=\"AIzaSyDpdSBqoGodLPlWy_K8ySLvbynlJk7JzWU\")\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.5-flash-preview-05-20\", contents=\"你好，你是谁？\"\n",
    ")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
